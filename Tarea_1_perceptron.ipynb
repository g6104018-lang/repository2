{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAFkZkQ4gZ06H3w8za/a+W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g6104018-lang/repository2/blob/main/Tarea_1_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncKiqdbiyzaV",
        "outputId": "7191c59b-dcc3-4e3c-f547-95e08da853ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos finales: [0.7895846  0.91741806]\n",
            "Bias final: [0.49253479]\n",
            "Entrada: [0 0], Salida esperada: 0, Salida del perceptrón: 0\n",
            "Entrada: [0 1], Salida esperada: 1, Salida del perceptrón: 1\n",
            "Entrada: [1 0], Salida esperada: 1, Salida del perceptrón: 1\n",
            "Entrada: [1 1], Salida esperada: 1, Salida del perceptrón: 1\n"
          ]
        }
      ],
      "source": [
        "# Perceptrón para la operación lógica OR\n",
        "import numpy as np\n",
        "\n",
        "# Entradas (X) y salidas deseadas (Y)\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1]\n",
        "])\n",
        "Y = np.array([0, 1, 1, 1])\n",
        "\n",
        "# Inicialización de pesos y sesgo (bias)\n",
        "w = np.random.rand(2)\n",
        "b = np.random.rand(1)\n",
        "lr = 0.1  # tasa de aprendizaje\n",
        "\n",
        "# Entrenamiento del perceptrón\n",
        "for epoch in range(20):\n",
        "    for i in range(len(X)):\n",
        "        # Calcular salida\n",
        "        z = np.dot(X[i], w) + b\n",
        "        y_pred = 1 if z >= 0.5 else 0\n",
        "\n",
        "        # Calcular error\n",
        "        error = Y[i] - y_pred\n",
        "\n",
        "        # Actualizar pesos y bias\n",
        "        w += lr * error * X[i]\n",
        "        b += lr * error\n",
        "\n",
        "print(\"Pesos finales:\", w)\n",
        "print(\"Bias final:\", b)\n",
        "\n",
        "# Prueba del modelo\n",
        "for i in range(len(X)):\n",
        "    z = np.dot(X[i], w) + b\n",
        "    y_pred = 1 if z >= 0.5 else 0\n",
        "    print(f\"Entrada: {X[i]}, Salida esperada: {Y[i]}, Salida del perceptrón: {y_pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La neurona recibe dos entradas (x₁, x₂).\n",
        "\n",
        "Cada entrada se multiplica por un peso (w₁, w₂) y se le suma un bias (b).\n",
        "\n",
        "Si el resultado es mayor o igual que 0.5, la neurona activa (da 1), de lo contrario 0.\n",
        "\n",
        "Durante el entrenamiento, ajusta los pesos y el bias según los errores que comete hasta que aprende correctamente."
      ],
      "metadata": {
        "id": "oHtnNLDMy6Pf"
      }
    }
  ]
}